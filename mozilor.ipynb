{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2ooMEy/eW9XA9MAQWPMEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riya2003-star/demo/blob/main/mozilor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qrGq13xzjEoi",
        "outputId": "27224153-2557-4aa5-bb3a-c6f2c6f9e8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: https://www.digitalsilk.com/\n",
            "Processing: https://www.baunfire.com/\n",
            "Processing: https://fourbynorth.com/\n",
            "\n",
            "Analysis Results:\n",
            "                        Website                                 Keywords  \\\n",
            "0  https://www.digitalsilk.com/                                      N/A   \n",
            "1     https://www.baunfire.com/  services, web design, agency, marketing   \n",
            "2      https://fourbynorth.com/                                 services   \n",
            "\n",
            "                                         AI Analysis  \\\n",
            "0  Error scraping https://www.digitalsilk.com/: 4...   \n",
            "1  Yes, the content belongs to an agency.\\n\\nThe ...   \n",
            "2  Yes, the content belongs to an agency.\\n\\nThe ...   \n",
            "\n",
            "                                   Decision  \n",
            "0                Reject (Unable to Analyze)  \n",
            "1               Onboard (Agency Identified)  \n",
            "2  Review Further (Relevant Keywords Found)  \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai # Import Gemini library\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Set Gemini API key\n",
        "genai.configure(api_key=\"AIzaSyBxpKU8ACgnXN-CndUmos7ZpOFYAXSpxYA\") # Replace with your key\n",
        "\n",
        "# Define website scraping function (remains the same)\n",
        "def scrape_website(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        return soup.get_text(strip=True)\n",
        "    except Exception as e:\n",
        "        return f\"Error scraping {url}: {str(e)}\"\n",
        "\n",
        "# Define keyword analysis function (remains the same)\n",
        "def analyze_keywords(content):\n",
        "    keywords = [\"services\", \"web design\", \"agency\", \"marketing\", \"branding\"]\n",
        "    found_keywords = [kw for kw in keywords if kw in content.lower()]\n",
        "    return found_keywords\n",
        "\n",
        "# Define Gemini analysis function\n",
        "def analyze_with_gemini(content):\n",
        "    try:\n",
        "        model = genai.GenerativeModel(\"gemini-pro\") # Use Gemini model\n",
        "        response = model.generate_content(\n",
        "            f\"Analyze the following content to determine if it belongs to an agency:\\n\\n{content}\"\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing content with Gemini: {str(e)}\"\n",
        "\n",
        "# Define the main processing function\n",
        "def process_websites(websites):\n",
        "    results = []\n",
        "    for website in websites:\n",
        "        print(f\"Processing: {website}\")\n",
        "        content = scrape_website(website)\n",
        "\n",
        "        if \"Error scraping\" in content:\n",
        "            results.append({\n",
        "                \"Website\": website,\n",
        "                \"Keywords\": \"N/A\",\n",
        "                \"AI Analysis\": content,\n",
        "                \"Decision\": \"Reject (Unable to Analyze)\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        found_keywords = analyze_keywords(content)\n",
        "        keyword_result = \", \".join(found_keywords) if found_keywords else \"No keywords found\"\n",
        "        ai_analysis = analyze_with_gemini(content[:1000])  # Limit to 1000 characters\n",
        "\n",
        "        # Decision logic (remains the same)\n",
        "        if found_keywords and \"agency\" in keyword_result:\n",
        "            decision = \"Onboard (Agency Identified)\"\n",
        "        elif found_keywords:\n",
        "            decision = \"Review Further (Relevant Keywords Found)\"\n",
        "        else:\n",
        "            decision = \"Reject (No Relevant Keywords)\"\n",
        "\n",
        "        results.append({\n",
        "            \"Website\": website,\n",
        "            \"Keywords\": keyword_result,\n",
        "            \"AI Analysis\": ai_analysis,\n",
        "            \"Decision\": decision\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Main execution block (remains the same)\n",
        "websites = [\n",
        "    \"https://www.digitalsilk.com/\",\n",
        "    \"https://www.baunfire.com/\",\n",
        "    \"https://fourbynorth.com/\"\n",
        "]\n",
        "\n",
        "results = process_websites(websites)\n",
        "\n",
        "# Save results to CSV (remains the same)\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"agency_analysis_results.csv\", index=False)\n",
        "\n",
        "# Display results (remains the same)\n",
        "print(\"\\nAnalysis Results:\")\n",
        "print(results_df)"
      ]
    }
  ]
}